pipeline:
  name: brain-mri-deploy
description: Deploys a model into production via the KServe Python SDK.
input:
  pfs:
    name: data
    repo: brain-mri-train
    branch: master
    glob: /
reprocess_spec: every_job                          # reprocess every datum even the input datums have not change. Another value is "until_success" and "every_job"
transform:
  cmd:
    - /bin/sh
  stdin:
    - export PYTHONUNBUFFERED=1
    - git clone https://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@github.com/boon1987/brain_mri.git /code
    - cd /code/pds_version/container/deploy
    - ls -l
    - pip install -r requirements.txt
    - python deploy.py --deployment-name brain-mri1 --cloud-model-bucket kserve-models --cloud-model-host s3
    - rm -rf /code
  #image: "hpelabssg/pdk:deploy_0.0.1"
  image: "hpelabssg/brain_mri_pdk:v1"
  secrets:
    - name: pachyderm-determined-pipeline-secret
      key: det_master
      env_var: DET_MASTER
    - name: pachyderm-determined-pipeline-secret
      key: det_user
      env_var: DET_USER
    - name: pachyderm-determined-pipeline-secret
      key: det_password
      env_var: DET_PASSWORD
    - name: pachyderm-determined-pipeline-secret
      key: kserve_namespace
      env_var: KSERVE_NAMESPACE
    - name: pachyderm-determined-pipeline-secret
      key: s3_endpoint
      env_var: S3_ENDPOINT
    - name: pachyderm-determined-pipeline-secret
      key: s3_access_key
      env_var: S3_ACCESS_KEY
    - name: pachyderm-determined-pipeline-secret
      key: s3_secret_key
      env_var: S3_SECRET_KEY
pod_patch: '[{"op": "add","path": "/volumes/-","value": {"name": "task-pv-storage","persistentVolumeClaim": {"claimName": "task-det-checkpoints-pvc"}}}, {"op": "add","path": "/containers/0/volumeMounts/-","value": {"mountPath": "/determined_shared_fs","name": "task-pv-storage"}}]'
